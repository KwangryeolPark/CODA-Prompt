{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from trainer import Trainer\n",
    "import learners\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(path):\n",
    "    class Namespace:\n",
    "        def __init__(self, **kwargs):\n",
    "            self.__dict__.update(kwargs)\n",
    "            \n",
    "        def __repr__(self):\n",
    "            return str(self.__dict__)\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        args = Namespace(**yaml.safe_load(f))\n",
    "    return args    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args('outputs/cifar-100/10-task/coda-p/args.yaml')\n",
    "\n",
    "# Train.\n",
    "# 최대한 trainer.py의 evaluate 함수를 그대로 사용하되, return_logits=True로 설정하여 logits를 반환하도록 수정\n",
    "seed = 0\n",
    "metric_keys = ['acc','time',]\n",
    "save_keys = ['global', 'pt', 'pt-local']\n",
    "\n",
    "trainer = Trainer(args, seed, metric_keys, save_keys)\n",
    "self = trainer\n",
    "\n",
    "self.learner = learners.__dict__[self.learner_type].__dict__[self.learner_name](self.learner_config)\n",
    "\n",
    "metric_table = {}\n",
    "metric_table_local = {}\n",
    "\n",
    "for i in range(self.max_task):\n",
    "\n",
    "    # increment task id in prompting modules\n",
    "    if i > 0:\n",
    "        try:\n",
    "            if self.learner.model.module.prompt is not None:\n",
    "                self.learner.model.module.prompt.process_task_count()\n",
    "        except:\n",
    "            if self.learner.model.prompt is not None:\n",
    "                self.learner.model.prompt.process_task_count()\n",
    "\n",
    "    # load model\n",
    "    model_save_dir = self.model_top_dir + '/models/repeat-'+str(self.seed+1)+'/task-'+self.task_names[i]+'/'\n",
    "    self.learner.task_count = i \n",
    "    self.learner.add_valid_output_dim(len(self.tasks_logits[i]))\n",
    "    self.learner.pre_steps()\n",
    "    self.learner.load_model(model_save_dir)\n",
    "\n",
    "    # set task id for model (needed for prompting)\n",
    "    try:\n",
    "        self.learner.model.module.task_id = i\n",
    "    except:\n",
    "        self.learner.model.task_id = i\n",
    "\n",
    "    self.reset_cluster_labels = True\n",
    "    for j in range(i+1):\n",
    "        if not i in metric_table:\n",
    "            metric_table[i] = {}\n",
    "        metric_table[i][j] = self.task_eval(j, return_logits=True)\n",
    "\n",
    "    for j in range(i+1):\n",
    "        if not i in metric_table_local:\n",
    "            metric_table_local[i] = {}\n",
    "        metric_table_local[i][j] = self.task_eval(j, local=True, return_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metric_table.pkl', 'wb') as f:\n",
    "    pickle.dump(metric_table, f)\n",
    "    \n",
    "with open('metric_table_local.pkl', 'wb') as f:\n",
    "    pickle.dump(metric_table_local, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
